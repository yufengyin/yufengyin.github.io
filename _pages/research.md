---
layout: archive
title: ""
permalink: /research/
author_profile: true
redirect_from:
  - /research
---

Research Experience
======
**Tsinghua University Human-Computer Speech Interaction Research Group**, 2016 to 2019

* Advisor: Prof. [Jia Jia](https://hcsi.cs.tsinghua.edu.cn/)

* <u>Understanding the Teaching Styles by an Attention based Multi-task Cross-media Dimensional Modeling</u> [[pdf]](https://yufengyin.github.io/files/mm19.pdf), 2018 to 2019
  * Established a fully-annotated voice data set (4,451 utterances) with pleasure and arousal values
  * Created a two-dimensional Teaching Style Semantic Space (TSSS) to determine teachersâ€™ teaching styles
  * Proposed a multi-task cross-media model to map acoustic features to coordinates on the TSSS
  * Co-authered a paper published in **ACM MM'19**

* <u>Inferring Emotions from Large-scale Internet Voice Data</u>  [[pdf]](https://yufengyin.github.io/files/tmm19.pdf), 2017 to 2018
  * Employed DNN and LSTM with autoencoders to infer emotions from large-scale internet voice data
  * Processed data, created neural networks, conducted experiments and edited the paper
  * Co-authored a paper published in **TMM'19**

* <u>Inferring Emotion from Conversational Voice Data: A Semi-supervised Multi-path Generative Neural Network Approach</u> [[pdf]](https://yufengyin.github.io/files/aaai18.pdf), 2017
  * Proposed a novel model to infer emotion from conversational voice data
  * Collected over 24,000 real-world utterance, processed data and edited paper
  * Co-authored a paper published in **AAAI'18**

**Stanford University Human-Computer Interaction Research Group**, 2018

* Advisors: Prof. [James Landay](https://profiles.stanford.edu/james-landay), Prof. [Emma Brunskill](https://cs.stanford.edu/people/ebrun/)

* <u>The Smart Primer</u> [[link](https://hci.stanford.edu/research/smartprimer/projects/smartprimer.html), [poster](https://yufengyin.github.io/files/poster.pdf), [slides](https://yufengyin.github.io/files/slides.pdf)], 2018
  * A personal tutor for children that uses narrative and embedded physical world activities to enhance learning
  * **Stanford University Undergraduate Visiting Research Program (UGVR)**
  * Created a chat bot and a quiz bot to guide users
  * Worked as the architect of the whole project for both frontend and backend coding
