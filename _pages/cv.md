---
layout: archive
title: ""
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

Education
======
* B.E. in Computer Science and Technologies, Tsinghua University, 2015 to 2019
* B.S. in Pure and Applied Mathematics (Second Major), Tsinghua University, 2016 to 2019
* Ph.D. in Computer Science, University of Southern California, 2019 to 2024 (expected)

Publications
======
* Suping Zhou, Jia Jia, **Yufeng Yin**, Xiang Li, Yang Yao, Ying Zhang, Zeyang Ye, Kehua Lei, Yan Huang, Jialie Shen. Understanding the Teaching Styles by an Attention based Multi-task Cross-media Dimensional Modeling. In the Proceedings of the 27th ACM International Conference on Multimedia (ACM MM'19) [[pdf]](https://yufengyin.github.io/files/mm19.pdf)
* Jia Jia, Suping Zhou, **Yufeng Yin** and Boya Wu. Inferring Emotions from Large-scale Internet Voice Data. IEEE Transactions on Multimedia 2019 (TMM'19) [[pdf]](https://yufengyin.github.io/files/tmm19.pdf)
* Suping Zhou, Jia Jia, Qi Wang, Yufei Dong, **Yufeng Yin** and Kehua Lei. Inferring Emotion from Conversational Voice Data: A Semi-supervised Multi-path Generative Neural Network Approach. In the Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI'18) [[pdf]](https://yufengyin.github.io/files/aaai18.pdf)

Awards & Honors
======
* Tsinghua University Department of Computer Science and Technologies Outstanding Graduates, 2019
* Tsinghua University Academic Excellence Scholarship (Top 10% of Department), 2017
* Tsinghua University Comprehensive Excellence Scholarship (Top 5% of Department) , 2016

Research Experience
======
**Tsinghua University Human-Computer Speech Interaction Research Group**, 2016 to 2019

* Advisor: Prof. [Jia Jia](https://hcsi.cs.tsinghua.edu.cn/)

* <u>Understanding the Teaching Styles by an Attention based Multi-task Cross-media Dimensional Modeling</u>, 2018 to 2019
  * Established a fully-annotated voice data set (4,451 utterances) with pleasure and arousal values
  * Created a two-dimensional Teaching Style Semantic Space (TSSS) to determine teachers’ teaching styles
  * Proposed a multi-task cross-media model to map acoustic features to coordinates on the TSSS
  * Co-authered a paper published in **ACM MM'19**

* <u>Inferring Emotions from Large-scale Internet Voice Data</u>, 2017 to 2018
  * Employed DNN and LSTM with autoencoders to infer emotions from large-scale internet voice data
  * Processed data, created neural networks, conducted experiments and edited the paper
  * Co-authored a paper published in **TMM'19**

* <u>Inferring Emotion from Conversational Voice Data: A Semi-supervised Multi-path Generative Neural Network Approach</u>, 2017
  * Proposed a novel model to infer emotion from conversational voice data
  * Collected over 24,000 real-world utterance, processed data and edited paper
  * Co-authored a paper published in **AAAI'18**

**Stanford University Human-Computer Interaction Research Group**, 2018

* Advisors: Prof. [James Landay](https://profiles.stanford.edu/james-landay), Prof. [Emma Brunskill](https://cs.stanford.edu/people/ebrun/)

* <u>The Smart Primer</u>, 2018
  * A personal tutor for children that uses narrative and embedded physical world activities to enhance learning
  * **Stanford University Undergraduate Visiting Research Program (UGVR)**
  * Created a chat bot and a quiz bot to guide users
  * Worked as the architect of the whole project for both frontend and backend coding

Work Experience
======
* Fall 2018: Teaching Assistant for Principles of Signal Processing
  * Tsinghua University
  * Helped Prof. Jia Jia to prepare lessons, especially those including mathematical derivations
  * Participated in editing slides, answering students’ questions and correcting homework

* Summer 2018: Research Assistant
  * Stanford University Human-Computer Interaction Research Group
  * Developed an educational software on tablets named the Smart Primer
  * Supervisor: Prof. James Landay, Prof. Emma Brunskill

Skills & Others
======
* Language: Mandarin, English
  * TOEFL iBT 100 (Reading 28, Listening 25, Speaking 22, Writing 25)
  * GRE Verbal 153 (61%), Quantitative 170 (96%), Analytical Writing 3.5 (41%)
* Programming Languages: C, C++, Python, Java, JavaScript, R, HTML, Assembly, LaTeX, Matlab, Qt
* Research Skills: vim, git, bash, cmake, gcc, gdb
* Software: Visual Studio, Android Studio, Eclipse
